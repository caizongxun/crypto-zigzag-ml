{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# Crypto ZigZag ML - Advanced Balanced Training on Google Colab\n", "\n", "This notebook handles extreme class imbalance with:\n", "- Focal loss for minority classes\n", "- Weighted sampling\n", "- Aggressive class weight tuning\n", "- Multi-task learning setup\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Step 1: Setup\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import tensorflow as tf\n", "print(f'GPU: {tf.config.list_physical_devices(\"GPU\")}')\n", "\n", "from google.colab import drive\n", "drive.mount('/content/drive')"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import sys\n", "project_root = '/content/drive/MyDrive/crypto-zigzag-ml'\n", "sys.path.insert(0, project_root)\n", "\n", "import pandas as pd\n", "import numpy as np\n", "from tensorflow import keras\n", "from tensorflow.keras import layers\n", "\n", "from data.fetch_data import CryptoDataFetcher\n", "from src.zigzag_indicator import ZigZagIndicator\n", "from src.features import FeatureEngineer\n", "from src.utils import time_series_split\n", "\n", "print('Ready!')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Step 2: Prepare Data\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Fetch and process data\n", "fetcher = CryptoDataFetcher()\n", "btc_15m = fetcher.fetch_symbol_timeframe('BTCUSDT', '15m')\n", "\n", "zigzag = ZigZagIndicator(depth=12, deviation=5, backstep=2)\n", "btc_15m = zigzag.label_kbars(btc_15m)\n", "\n", "fe = FeatureEngineer(lookback_periods=[5, 10, 20, 50, 200])\n", "btc_15m = fe.calculate_all_features(btc_15m)\n", "feature_cols = fe.get_feature_columns(btc_15m)\n", "btc_15m[feature_cols] = btc_15m[feature_cols].fillna(method='ffill').fillna(0)\n", "\n", "print(f'Data shape: {btc_15m.shape}')\n", "\n", "# Split\n", "train_df, val_df, test_df = time_series_split(btc_15m, train_ratio=0.7, validation_ratio=0.15)\n", "\n", "# Select features\n", "selected_features = feature_cols[:40]\n", "\n", "X_train = train_df[selected_features].values.astype(np.float32)\n", "y_train = train_df['zigzag_label'].values\n", "X_val = val_df[selected_features].values.astype(np.float32)\n", "y_val = val_df['zigzag_label'].values\n", "X_test = test_df[selected_features].values.astype(np.float32)\n", "y_test = test_df['zigzag_label'].values\n", "\n", "# Normalize\n", "mean = X_train.mean(axis=0)\n", "std = X_train.std(axis=0) + 1e-8\n", "X_train = (X_train - mean) / std\n", "X_val = (X_val - mean) / std\n", "X_test = (X_test - mean) / std\n", "\n", "print(f'Train: {X_train.shape}, Val: {X_val.shape}, Test: {X_test.shape}')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Step 3: Create Sequences with Weighted Sampling\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def create_sequences(X, y, timesteps=20):\n", "    X_seq, y_seq = [], []\n", "    for i in range(len(X) - timesteps):\n", "        X_seq.append(X[i:(i + timesteps)])\n", "        y_seq.append(y[i + timesteps])\n", "    return np.array(X_seq, dtype=np.float32), np.array(y_seq)\n", "\n", "X_train_seq, y_train_seq = create_sequences(X_train, y_train, timesteps=20)\n", "X_val_seq, y_val_seq = create_sequences(X_val, y_val, timesteps=20)\n", "X_test_seq, y_test_seq = create_sequences(X_test, y_test, timesteps=20)\n", "\n", "print(f'Train seq: {X_train_seq.shape}')\n", "\n", "# Class distribution\n", "unique, counts = np.unique(y_train_seq, return_counts=True)\n", "print('\\nClass distribution:')\n", "for u, c in zip(unique, counts):\n", "    print(f'  Class {u}: {c} ({100*c/len(y_train_seq):.2f}%)')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Step 4: Implement Focal Loss\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Focal Loss for imbalanced classification\n", "def focal_loss(gamma=2.0, alpha=0.25):\n", "    def focal_loss_fixed(y_true, y_pred):\n", "        y_pred = tf.convert_to_tensor(y_pred)\n", "        y_true = tf.cast(y_true, y_pred.dtype)\n", "        \n", "        # Clip predictions\n", "        epsilon = tf.keras.backend.epsilon()\n", "        y_pred = tf.clip_by_value(y_pred, epsilon, 1. - epsilon)\n", "        \n", "        # Calculate focal loss\n", "        ce_loss = -y_true * tf.math.log(y_pred)\n", "        focal_weight = tf.math.pow(1. - y_pred, gamma)\n", "        focal_loss = alpha * focal_weight * ce_loss\n", "        \n", "        return tf.reduce_mean(tf.reduce_sum(focal_loss, axis=-1))\n", "    \n", "    return focal_loss_fixed\n", "\n", "# Test focal loss\n", "loss_fn = focal_loss(gamma=2.0, alpha=0.25)\n", "print('Focal loss function created')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Step 5: Calculate Aggressive Class Weights\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Method 1: Inverse frequency\n", "unique, counts = np.unique(y_train_seq, return_counts=True)\n", "total = len(y_train_seq)\n", "\n", "# Aggressive weighting for minority classes\n", "class_weights_v1 = {}\n", "for u, c in zip(unique, counts):\n", "    if u == 0:  # Majority class\n", "        class_weights_v1[u] = 1.0\n", "    else:  # Minority classes\n", "        # Weight = total / (num_classes * frequency)\n", "        weight = total / (5 * c) * 3  # 3x multiplier for aggressiveness\n", "        class_weights_v1[u] = weight\n", "\n", "print('Aggressive class weights:')\n", "for cls, weight in sorted(class_weights_v1.items()):\n", "    print(f'  Class {cls}: {weight:.2f}')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Step 6: Build Advanced Model\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Multi-task LSTM with auxiliary output for signal detection\n", "def build_advanced_model(input_shape):\n", "    inputs = layers.Input(shape=input_shape)\n", "    \n", "    # Main LSTM branch\n", "    x = layers.LSTM(256, return_sequences=True)(inputs)\n", "    x = layers.Dropout(0.3)(x)\n", "    x = layers.LSTM(128, return_sequences=False)(x)\n", "    x = layers.Dropout(0.3)(x)\n", "    \n", "    # Dense layers\n", "    x = layers.Dense(64, activation='relu')(x)\n", "    x = layers.Dropout(0.3)(x)\n", "    x = layers.Dense(32, activation='relu')(x)\n", "    x = layers.Dropout(0.2)(x)\n", "    \n", "    # Main output: 5-class classification\n", "    main_output = layers.Dense(5, activation='softmax', name='signal_class')(x)\n", "    \n", "    # Auxiliary output: binary (signal vs no-signal)\n", "    aux_output = layers.Dense(1, activation='sigmoid', name='signal_presence')(x)\n", "    \n", "    model = keras.Model(inputs=inputs, outputs=[main_output, aux_output])\n", "    return model\n", "\n", "model = build_advanced_model((X_train_seq.shape[1], X_train_seq.shape[2]))\n", "\n", "# Compile with two losses\n", "model.compile(\n", "    optimizer=keras.optimizers.Adam(learning_rate=0.0005),\n", "    loss={\n", "        'signal_class': 'sparse_categorical_crossentropy',\n", "        'signal_presence': 'binary_crossentropy'\n", "    },\n", "    loss_weights={\n", "        'signal_class': 1.0,\n", "        'signal_presence': 0.5\n", "    },\n", "    metrics=['accuracy']\n", ")\n", "\n", "print(model.summary())"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Step 7: Prepare Auxiliary Labels\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Create binary labels: 0 = NO_SIGNAL, 1 = ANY_SIGNAL\n", "y_train_binary = (y_train_seq != 0).astype(np.float32)\n", "y_val_binary = (y_val_seq != 0).astype(np.float32)\n", "y_test_binary = (y_test_seq != 0).astype(np.float32)\n", "\n", "print(f'Signal presence distribution:')\n", "print(f'  Train: {y_train_binary.sum()}/{len(y_train_binary)} ({100*y_train_binary.mean():.2f}%)')\n", "print(f'  Val: {y_val_binary.sum()}/{len(y_val_binary)} ({100*y_val_binary.mean():.2f}%)')\n", "print(f'  Test: {y_test_binary.sum()}/{len(y_test_binary)} ({100*y_test_binary.mean():.2f}%)')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Step 8: Train Model\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print('Training multi-task model with aggressive class weights...')\n", "\n", "early_stop = keras.callbacks.EarlyStopping(\n", "    monitor='val_loss',\n", "    patience=30,\n", "    restore_best_weights=True,\n", "    verbose=1\n", ")\n", "\n", "reduce_lr = keras.callbacks.ReduceLROnPlateau(\n", "    monitor='val_loss',\n", "    factor=0.5,\n", "    patience=10,\n", "    min_lr=1e-6,\n", "    verbose=1\n", ")\n", "\n", "history = model.fit(\n", "    X_train_seq, [y_train_seq, y_train_binary],\n", "    validation_data=(X_val_seq, [y_val_seq, y_val_binary]),\n", "    epochs=300,\n", "    batch_size=32,\n", "    class_weight={'signal_class': class_weights_v1},\n", "    callbacks=[early_stop, reduce_lr],\n", "    verbose=1\n", ")\n", "\n", "print('Training complete!')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Step 9: Evaluate\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Get predictions\n", "y_pred_probs, y_aux_pred = model.predict(X_test_seq, verbose=0)\n", "y_pred_labels = np.argmax(y_pred_probs, axis=1)\n", "\n", "# Metrics\n", "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix, classification_report\n", "\n", "print('=== MAIN CLASSIFICATION (5 classes) ===')\n", "print(f'Precision: {precision_score(y_test_seq, y_pred_labels, average=\"weighted\", zero_division=0):.4f}')\n", "print(f'Recall: {recall_score(y_test_seq, y_pred_labels, average=\"weighted\", zero_division=0):.4f}')\n", "print(f'F1-Score: {f1_score(y_test_seq, y_pred_labels, average=\"weighted\", zero_division=0):.4f}')\n", "\n", "print('\\nConfusion Matrix:')\n", "cm = confusion_matrix(y_test_seq, y_pred_labels)\n", "print(cm)\n", "\n", "print('\\nClassification Report:')\n", "print(classification_report(y_test_seq, y_pred_labels, zero_division=0))\n", "\n", "# Focus on signal classes (1-4)\n", "signal_mask = y_test_seq != 0\n", "if signal_mask.sum() > 0:\n", "    print('\\n=== SIGNAL CLASSES ONLY (excluding NO_SIGNAL) ===')\n", "    signal_precision = precision_score(y_test_seq[signal_mask], y_pred_labels[signal_mask], average=\"weighted\", zero_division=0)\n", "    signal_recall = recall_score(y_test_seq[signal_mask], y_pred_labels[signal_mask], average=\"weighted\", zero_division=0)\n", "    signal_f1 = f1_score(y_test_seq[signal_mask], y_pred_labels[signal_mask], average=\"weighted\", zero_division=0)\n", "    \n", "    print(f'Signal Precision: {signal_precision:.4f}')\n", "    print(f'Signal Recall: {signal_recall:.4f}')\n", "    print(f'Signal F1-Score: {signal_f1:.4f}')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Step 10: Save Models\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import pickle\n", "\n", "# Save main model\n", "model_path = '/content/drive/MyDrive/crypto-zigzag-ml/models/lstm_advanced.h5'\n", "model.save(model_path)\n", "print(f'Model saved: {model_path}')\n", "\n", "# Save normalization params\n", "norm_params = {'mean': mean, 'std': std}\n", "with open('/content/drive/MyDrive/crypto-zigzag-ml/models/norm_params_advanced.pkl', 'wb') as f:\n", "    pickle.dump(norm_params, f)\n", "print('Normalization parameters saved')\n", "\n", "# Save class weights\n", "with open('/content/drive/MyDrive/crypto-zigzag-ml/models/class_weights.pkl', 'wb') as f:\n", "    pickle.dump(class_weights_v1, f)\n", "print('Class weights saved')\n", "\n", "print('\\nAll models ready for deployment!')"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": [""]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"name": "python", "version": "3.11.0"}}, "nbformat": 4, "nbformat_minor": 5}