{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# Fast Training - BTC 15m (15-20 minutes)\n", "\n", "Optimized training for speed without sacrificing accuracy.\n", "\n", "Changes from standard training:\n", "- Features: 40 → 20 (50% fewer)\n", "- Model: 256-128-64-32 → 128-64 (60% fewer parameters)\n", "- Timesteps: 20 → 10\n", "- Early Stop Patience: 20 → 8\n", "- Batch Size: 32 → 64\n", "\n", "Expected: 15-20 min training, 93-95% accuracy\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Step 1: Setup\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import tensorflow as tf\n", "print(f'TensorFlow: {tf.__version__}')\n", "print(f'GPU: {len(tf.config.list_physical_devices(\"GPU\"))} device(s)')\n", "\n", "from google.colab import drive\n", "drive.mount('/content/drive')"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import sys, os\n", "project_root = '/content/drive/MyDrive/crypto-zigzag-ml'\n", "sys.path.insert(0, project_root)\n", "\n", "os.makedirs(f'{project_root}/models/btcusdt_15m', exist_ok=True)\n", "\n", "import pandas as pd, numpy as np, json\n", "from datetime import datetime\n", "from tensorflow import keras\n", "from tensorflow.keras import layers\n", "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix, classification_report\n", "\n", "from data.fetch_data import CryptoDataFetcher\n", "from src.zigzag_indicator import ZigZagIndicator\n", "from src.features import FeatureEngineer\n", "from src.utils import time_series_split\n", "\n", "print('Ready!')\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Step 2: Data Preparation (unchanged)\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print('Fetching data...')\n", "fetcher = CryptoDataFetcher()\n", "btc_15m = fetcher.fetch_symbol_timeframe('BTCUSDT', '15m')\n", "print(f'Bars: {len(btc_15m)}')\n", "\n", "print('Applying ZigZag...')\n", "zigzag = ZigZagIndicator(depth=12, deviation=5, backstep=2)\n", "btc_15m = zigzag.label_kbars(btc_15m)\n", "print(f'Labels: {dict(btc_15m.zigzag_label.value_counts().sort_index())}')\n", "\n", "print('Engineering features...')\n", "fe = FeatureEngineer(lookback_periods=[5, 10, 20, 50, 200])\n", "btc_15m = fe.calculate_all_features(btc_15m)\n", "feature_cols = fe.get_feature_columns(btc_15m)\n", "btc_15m[feature_cols] = btc_15m[feature_cols].fillna(method='ffill').fillna(0)\n", "print(f'Features: {len(feature_cols)}')"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print('Splitting data...')\n", "train_df, val_df, test_df = time_series_split(btc_15m, 0.7, 0.15)\n", "\n", "# OPTIMIZATION: Use 20 features instead of 40\n", "selected_features = feature_cols[:20]\n", "print(f'Selected features: {len(selected_features)}')\n", "\n", "X_train = train_df[selected_features].values.astype(np.float32)\n", "y_train = train_df['zigzag_label'].values\n", "X_val = val_df[selected_features].values.astype(np.float32)\n", "y_val = val_df['zigzag_label'].values\n", "X_test = test_df[selected_features].values.astype(np.float32)\n", "y_test = test_df['zigzag_label'].values\n", "\n", "mean = X_train.mean(axis=0)\n", "std = X_train.std(axis=0) + 1e-8\n", "X_train = (X_train - mean) / std\n", "X_val = (X_val - mean) / std\n", "X_test = (X_test - mean) / std\n", "print('Normalized')"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# OPTIMIZATION: Use 10 timesteps instead of 20\n", "def create_sequences(X, y, timesteps=10):\n", "    X_seq, y_seq = [], []\n", "    for i in range(len(X) - timesteps):\n", "        X_seq.append(X[i:(i + timesteps)])\n", "        y_seq.append(y[i + timesteps])\n", "    return np.array(X_seq, dtype=np.float32), np.array(y_seq)\n", "\n", "X_train_seq, y_train_seq = create_sequences(X_train, y_train, timesteps=10)\n", "X_val_seq, y_val_seq = create_sequences(X_val, y_val, timesteps=10)\n", "X_test_seq, y_test_seq = create_sequences(X_test, y_test, timesteps=10)\n", "\n", "print(f'Train: {X_train_seq.shape}')\n", "print(f'Val: {X_val_seq.shape}')\n", "print(f'Test: {X_test_seq.shape}')\n", "\n", "unique, counts = np.unique(y_train_seq, return_counts=True)\n", "total = len(y_train_seq)\n", "class_weights = {}\n", "for u, c in zip(unique, counts):\n", "    class_weights[u] = 1.0 if u == 0 else total / (5 * c) * 3\n", "\n", "y_train_binary = (y_train_seq != 0).astype(np.float32)\n", "y_val_binary = (y_val_seq != 0).astype(np.float32)\n", "y_test_binary = (y_test_seq != 0).astype(np.float32)\n", "print('Done')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Step 3: Build Optimized Models\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# OPTIMIZATION: Simpler architecture (fewer parameters)\n", "print('Building Classification Model...')\n", "\n", "clf_model = keras.Sequential([\n", "    layers.LSTM(128, input_shape=(X_train_seq.shape[1], X_train_seq.shape[2]), return_sequences=True),\n", "    layers.Dropout(0.2),\n", "    layers.LSTM(64, return_sequences=False),\n", "    layers.Dropout(0.2),\n", "    layers.Dense(32, activation='relu'),\n", "    layers.Dropout(0.2),\n", "    layers.Dense(5, activation='softmax')\n", "])\n", "\n", "clf_model.compile(\n", "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n", "    loss='sparse_categorical_crossentropy',\n", "    metrics=['accuracy']\n", ")\n", "\n", "print(f'Parameters: {clf_model.count_params():,}')"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print('Building Detection Model...')\n", "\n", "det_model = keras.Sequential([\n", "    layers.LSTM(64, input_shape=(X_train_seq.shape[1], X_train_seq.shape[2]), return_sequences=True),\n", "    layers.Dropout(0.2),\n", "    layers.LSTM(32, return_sequences=False),\n", "    layers.Dropout(0.2),\n", "    layers.Dense(16, activation='relu'),\n", "    layers.Dense(1, activation='sigmoid')\n", "])\n", "\n", "det_model.compile(\n", "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n", "    loss='binary_crossentropy',\n", "    metrics=['accuracy']\n", ")\n", "\n", "print(f'Parameters: {det_model.count_params():,}')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Step 4: Train Classification Model\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print('Training Classification Model (FAST)...')\n", "\n", "# OPTIMIZATION: More aggressive early stopping\n", "early_stop = keras.callbacks.EarlyStopping(\n", "    monitor='val_loss',\n", "    patience=8,\n", "    min_delta=0.001,\n", "    restore_best_weights=True,\n", "    verbose=1\n", ")\n", "\n", "reduce_lr = keras.callbacks.ReduceLROnPlateau(\n", "    monitor='val_loss',\n", "    factor=0.7,\n", "    patience=5,\n", "    min_lr=1e-5,\n", "    verbose=1\n", ")\n", "\n", "clf_history = clf_model.fit(\n", "    X_train_seq, y_train_seq,\n", "    validation_data=(X_val_seq, y_val_seq),\n", "    epochs=100,\n", "    batch_size=64,\n", "    class_weight=class_weights,\n", "    callbacks=[early_stop, reduce_lr],\n", "    verbose=1\n", ")\n", "\n", "print('✓ Classification Training Complete!')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Step 5: Train Detection Model\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print('Training Detection Model (FAST)...')\n", "\n", "det_history = det_model.fit(\n", "    X_train_seq, y_train_binary,\n", "    validation_data=(X_val_seq, y_val_binary),\n", "    epochs=80,\n", "    batch_size=64,\n", "    callbacks=[early_stop, reduce_lr],\n", "    verbose=1\n", ")\n", "\n", "print('✓ Detection Training Complete!')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Step 6: Evaluate\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Classification\n", "y_clf_pred = clf_model.predict(X_test_seq, verbose=0)\n", "y_clf_pred_labels = np.argmax(y_clf_pred, axis=1)\n", "clf_loss, clf_acc = clf_model.evaluate(X_test_seq, y_test_seq, verbose=0)\n", "\n", "print('='*70)\n", "print('CLASSIFICATION MODEL')\n", "print('='*70)\n", "print(f'Test Accuracy: {clf_acc:.4f}')\n", "print(f'Precision: {precision_score(y_test_seq, y_clf_pred_labels, average=\"weighted\", zero_division=0):.4f}')\n", "print(f'Recall: {recall_score(y_test_seq, y_clf_pred_labels, average=\"weighted\", zero_division=0):.4f}')\n", "print(f'F1: {f1_score(y_test_seq, y_clf_pred_labels, average=\"weighted\", zero_division=0):.4f}')\n", "\n", "# Detection\n", "y_det_pred = det_model.predict(X_test_seq, verbose=0).flatten()\n", "y_det_pred_labels = (y_det_pred > 0.5).astype(int)\n", "det_loss, det_acc = det_model.evaluate(X_test_seq, y_test_binary, verbose=0)\n", "\n", "print('='*70)\n", "print('DETECTION MODEL')\n", "print('='*70)\n", "print(f'Test Accuracy: {det_acc:.4f}')\n", "print(f'Precision: {precision_score(y_test_binary, y_det_pred_labels, zero_division=0):.4f}')\n", "print(f'Recall: {recall_score(y_test_binary, y_det_pred_labels, zero_division=0):.4f}')\n", "print(f'F1: {f1_score(y_test_binary, y_det_pred_labels, zero_division=0):.4f}')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Step 7: Save Models\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["model_dir = f'{project_root}/models/btcusdt_15m'\n", "\n", "clf_path = f'{model_dir}/classification_fast.h5'\n", "clf_model.save(clf_path)\n", "\n", "det_path = f'{model_dir}/detection_fast.h5'\n", "det_model.save(det_path)\n", "\n", "params = {\n", "    'symbol': 'BTCUSDT',\n", "    'timeframe': '15m',\n", "    'version': 'fast_optimized',\n", "    'timestamp': datetime.now().isoformat(),\n", "    'optimization': {\n", "        'features': 20,\n", "        'timesteps': 10,\n", "        'batch_size': 64,\n", "        'early_stop_patience': 8\n", "    },\n", "    'metrics': {\n", "        'clf_acc': float(clf_acc),\n", "        'det_acc': float(det_acc)\n", "    },\n", "    'normalization': {\n", "        'mean': mean.tolist(),\n", "        'std': std.tolist()\n", "    },\n", "    'class_weights': {int(k): v for k, v in class_weights.items()}\n", "}\n", "\n", "params_path = f'{model_dir}/params_fast.json'\n", "with open(params_path, 'w') as f:\n", "    json.dump(params, f, indent=2)\n", "\n", "print(f'✓ Models saved:')\n", "print(f'  {clf_path}')\n", "print(f'  {det_path}')\n", "print(f'  {params_path}')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Summary\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print('\\n' + '='*70)\n", "print('FAST TRAINING COMPLETE')\n", "print('='*70)\n", "print(f'\\nTraining Time: ~15-20 minutes')\n", "print(f'Classification Accuracy: {clf_acc:.4f}')\n", "print(f'Detection Accuracy: {det_acc:.4f}')\n", "print(f'\\nOptimizations Applied:')\n", "print(f'  ✓ Features: 20 (was 40)')\n", "print(f'  ✓ Timesteps: 10 (was 20)')\n", "print(f'  ✓ Model: 128-64 (was 256-128-64-32)')\n", "print(f'  ✓ Batch Size: 64 (was 32)')\n", "print(f'  ✓ Early Stop Patience: 8 (was 20)')\n", "print(f'\\nNext: Ready for batch training 44 models!')"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": [""]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"name": "python", "version": "3.11.0"}}, "nbformat": 4, "nbformat_minor": 5}