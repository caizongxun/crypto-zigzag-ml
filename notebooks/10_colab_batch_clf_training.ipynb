{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# Colab Batch Training - Classification Models Only\n", "\n", "Train 44 classification models (5-class signal classifier)\n", "- 22 symbols × 2 timeframes = 44 models\n", "- Each model: 15-20 minutes\n", "- Total: 11-15 hours on Colab GPU\n", "\n", "Optimizations:\n", "- Features: 20\n", "- Timesteps: 10\n", "- Model: 128-64 LSTM\n", "- Batch: 64\n", "- Early Stop: 8\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Step 1: Setup\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import tensorflow as tf\n", "print(f'TensorFlow: {tf.__version__}')\n", "print(f'GPU: {tf.config.list_physical_devices(\"GPU\")}')\n", "\n", "from google.colab import drive\n", "drive.mount('/content/drive')"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import sys, os\n", "project_root = '/content/drive/MyDrive/crypto-zigzag-ml'\n", "sys.path.insert(0, project_root)\n", "\n", "import pandas as pd, numpy as np, json\n", "from datetime import datetime\n", "from tensorflow import keras\n", "from tensorflow.keras import layers\n", "from sklearn.metrics import precision_score, recall_score, f1_score\n", "\n", "from data.fetch_data import CryptoDataFetcher\n", "from src.zigzag_indicator import ZigZagIndicator\n", "from src.features import FeatureEngineer\n", "from src.utils import time_series_split\n", "\n", "print('Ready!')\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Step 2: Configuration\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["SYMBOLS = [\n", "    'BTCUSDT', 'ETHUSDT', 'BNBUSDT', 'XRPUSDT', 'ADAUSDT',\n", "    'DOGEUSDT', 'MATICUSDT', 'LINKUSDT', 'LITUSDT', 'UNIUSDT',\n", "    'AVAXUSDT', 'SOLUUSDT', 'FTMUSDT', 'AAVEUSDT', 'CRVUSDT',\n", "    'MKRUSDT', 'SNXUSDT', 'COMPUSDT', 'LRCUSDT', 'GRTUSDT',\n", "    'ALGOUSDT', 'ATOMUSDT'\n", "]\n", "\n", "TIMEFRAMES = ['15m', '1h']\n", "\n", "CONFIG = {\n", "    'features': 20,\n", "    'timesteps': 10,\n", "    'batch_size': 64,\n", "    'epochs': 100,\n", "    'early_stop_patience': 8,\n", "    'lstm_layers': [128, 64],\n", "}\n", "\n", "print(f'Symbols: {len(SYMBOLS)}')\n", "print(f'Timeframes: {len(TIMEFRAMES)}')\n", "print(f'Total models: {len(SYMBOLS) * len(TIMEFRAMES)}')\n", "print(f'Estimated time: {len(SYMBOLS) * len(TIMEFRAMES) * 0.3:.1f} hours')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Step 3: Helper Functions\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def create_sequences(X, y, timesteps=10):\n", "    X_seq, y_seq = [], []\n", "    for i in range(len(X) - timesteps):\n", "        X_seq.append(X[i:(i + timesteps)])\n", "        y_seq.append(y[i + timesteps])\n", "    return np.array(X_seq, dtype=np.float32), np.array(y_seq)\n", "\n", "def build_clf_model(input_shape):\n", "    model = keras.Sequential([\n", "        layers.LSTM(CONFIG['lstm_layers'][0], input_shape=input_shape, return_sequences=True),\n", "        layers.Dropout(0.2),\n", "        layers.LSTM(CONFIG['lstm_layers'][1], return_sequences=False),\n", "        layers.Dropout(0.2),\n", "        layers.Dense(32, activation='relu'),\n", "        layers.Dropout(0.2),\n", "        layers.Dense(5, activation='softmax')\n", "    ])\n", "    model.compile(\n", "        optimizer=keras.optimizers.Adam(learning_rate=0.001),\n", "        loss='sparse_categorical_crossentropy',\n", "        metrics=['accuracy']\n", "    )\n", "    return model\n", "\n", "print('Functions ready')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Step 4: Training Function\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def train_clf_model(symbol, timeframe, fetcher, zigzag, fe):\n", "    try:\n", "        # Data\n", "        data = fetcher.fetch_symbol_timeframe(symbol, timeframe)\n", "        if len(data) < 500:\n", "            return {'symbol': symbol, 'timeframe': timeframe, 'status': 'skip', 'reason': 'insufficient_data'}\n", "        \n", "        # ZigZag\n", "        data = zigzag.label_kbars(data)\n", "        \n", "        # Features\n", "        data = fe.calculate_all_features(data)\n", "        feature_cols = fe.get_feature_columns(data)\n", "        data[feature_cols] = data[feature_cols].fillna(method='ffill').fillna(0)\n", "        \n", "        # Split\n", "        train_df, val_df, test_df = time_series_split(data, 0.7, 0.15)\n", "        selected_features = feature_cols[:CONFIG['features']]\n", "        \n", "        X_train = train_df[selected_features].values.astype(np.float32)\n", "        y_train = train_df['zigzag_label'].values\n", "        X_val = val_df[selected_features].values.astype(np.float32)\n", "        y_val = val_df['zigzag_label'].values\n", "        X_test = test_df[selected_features].values.astype(np.float32)\n", "        y_test = test_df['zigzag_label'].values\n", "        \n", "        # Normalize\n", "        mean = X_train.mean(axis=0)\n", "        std = X_train.std(axis=0) + 1e-8\n", "        X_train = (X_train - mean) / std\n", "        X_val = (X_val - mean) / std\n", "        X_test = (X_test - mean) / std\n", "        \n", "        # Sequences\n", "        X_train_seq, y_train_seq = create_sequences(X_train, y_train, CONFIG['timesteps'])\n", "        X_val_seq, y_val_seq = create_sequences(X_val, y_val, CONFIG['timesteps'])\n", "        X_test_seq, y_test_seq = create_sequences(X_test, y_test, CONFIG['timesteps'])\n", "        \n", "        # Class weights\n", "        unique, counts = np.unique(y_train_seq, return_counts=True)\n", "        total = len(y_train_seq)\n", "        class_weights = {}\n", "        for u, c in zip(unique, counts):\n", "            class_weights[u] = 1.0 if u == 0 else total / (5 * c) * 3\n", "        \n", "        # Early stopping\n", "        early_stop = keras.callbacks.EarlyStopping(\n", "            monitor='val_loss',\n", "            patience=CONFIG['early_stop_patience'],\n", "            restore_best_weights=True,\n", "            verbose=0\n", "        )\n", "        \n", "        # Train\n", "        model = build_clf_model((X_train_seq.shape[1], X_train_seq.shape[2]))\n", "        model.fit(\n", "            X_train_seq, y_train_seq,\n", "            validation_data=(X_val_seq, y_val_seq),\n", "            epochs=CONFIG['epochs'],\n", "            batch_size=CONFIG['batch_size'],\n", "            class_weight=class_weights,\n", "            callbacks=[early_stop],\n", "            verbose=0\n", "        )\n", "        \n", "        # Evaluate\n", "        loss, acc = model.evaluate(X_test_seq, y_test_seq, verbose=0)\n", "        y_pred = model.predict(X_test_seq, verbose=0)\n", "        y_pred_labels = np.argmax(y_pred, axis=1)\n", "        precision = precision_score(y_test_seq, y_pred_labels, average='weighted', zero_division=0)\n", "        recall = recall_score(y_test_seq, y_pred_labels, average='weighted', zero_division=0)\n", "        f1 = f1_score(y_test_seq, y_pred_labels, average='weighted', zero_division=0)\n", "        \n", "        # Save\n", "        model_dir = f'{project_root}/models/{symbol.lower()}_{timeframe}/'\n", "        os.makedirs(model_dir, exist_ok=True)\n", "        \n", "        model.save(f'{model_dir}classification.h5')\n", "        \n", "        params = {\n", "            'symbol': symbol, 'timeframe': timeframe,\n", "            'timestamp': datetime.now().isoformat(),\n", "            'metrics': {'acc': float(acc), 'precision': float(precision), 'recall': float(recall), 'f1': float(f1)},\n", "            'normalization': {'mean': mean.tolist(), 'std': std.tolist()},\n", "            'class_weights': {int(k): v for k, v in class_weights.items()}\n", "        }\n", "        with open(f'{model_dir}params.json', 'w') as f:\n", "            json.dump(params, f, indent=2)\n", "        \n", "        return {\n", "            'symbol': symbol,\n", "            'timeframe': timeframe,\n", "            'status': 'ok',\n", "            'acc': float(acc),\n", "            'precision': float(precision),\n", "            'recall': float(recall),\n", "            'f1': float(f1)\n", "        }\n", "    \n", "    except Exception as e:\n", "        return {\n", "            'symbol': symbol,\n", "            'timeframe': timeframe,\n", "            'status': 'error',\n", "            'error': str(e)[:100]\n", "        }\n", "\n", "print('Training function ready')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Step 5: Batch Training\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["fetcher = CryptoDataFetcher()\n", "zigzag = ZigZagIndicator(depth=12, deviation=5, backstep=2)\n", "fe = FeatureEngineer(lookback_periods=[5, 10, 20, 50, 200])\n", "\n", "results = []\n", "start_time = datetime.now()\n", "\n", "print('='*70)\n", "print('BATCH TRAINING - CLASSIFICATION MODELS')\n", "print('='*70)\n", "\n", "for i, symbol in enumerate(SYMBOLS, 1):\n", "    for j, timeframe in enumerate(TIMEFRAMES, 1):\n", "        model_num = (i-1) * len(TIMEFRAMES) + j\n", "        print(f'[{model_num}/44] {symbol} {timeframe}... ', end='', flush=True)\n", "        \n", "        result = train_clf_model(symbol, timeframe, fetcher, zigzag, fe)\n", "        results.append(result)\n", "        \n", "        if result['status'] == 'ok':\n", "            print(f"✓ acc={result['acc']:.4f}")\n", "        elif result['status'] == 'skip':\n", "            print(f"⊘ {result['reason']}")\n", "        else:\n", "            print(f"✗ {result.get('error', 'unknown error')}")\n", "\n", "print('='*70)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Step 6: Summary\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["total_time = (datetime.now() - start_time).total_seconds() / 3600\n", "\n", "successful = [r for r in results if r['status'] == 'ok']\n", "failed = [r for r in results if r['status'] == 'error']\n", "skipped = [r for r in results if r['status'] == 'skip']\n", "\n", "print()\n", "print('='*70)\n", "print('BATCH TRAINING SUMMARY')\n", "print('='*70)\n", "print(f'Total time: {total_time:.1f} hours ({total_time*60:.0f} minutes)')\n", "print(f'Completed: {len(successful)}/{len(results)}')\n", "print(f'Failed: {len(failed)}')\n", "print(f'Skipped: {len(skipped)}')\n", "\n", "if successful:\n", "    avg_acc = np.mean([r['acc'] for r in successful])\n", "    avg_precision = np.mean([r['precision'] for r in successful])\n", "    avg_recall = np.mean([r['recall'] for r in successful])\n", "    avg_f1 = np.mean([r['f1'] for r in successful])\n", "    \n", "    print(f'\\nAverage Metrics:')\n", "    print(f'  Accuracy: {avg_acc:.4f}')\n", "    print(f'  Precision: {avg_precision:.4f}')\n", "    print(f'  Recall: {avg_recall:.4f}')\n", "    print(f'  F1-Score: {avg_f1:.4f}')\n", "    \n", "    # Top 5\n", "    sorted_by_acc = sorted(successful, key=lambda x: x['acc'], reverse=True)[:5]\n", "    print(f'\\nTop 5 Models:')\n", "    for r in sorted_by_acc:\n", "        print(f'  {r[\"symbol\"]:10s} {r[\"timeframe\"]:3s}: {r[\"acc\"]:6.4f}')\n", "\n", "if failed:\n", "    print(f'\\nFailed Models:')\n", "    for r in failed:\n", "        print(f'  {r[\"symbol\"]:10s} {r[\"timeframe\"]:3s}: {r.get(\"error\", \"unknown\")}')\n", "\n", "print('='*70)\n", "print('All models saved to Google Drive:')\n", "print('crypto-zigzag-ml/models/')\n", "print('='*70)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Step 7: Verify Models\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import os\n", "\n", "model_base = f'{project_root}/models'\n", "model_dirs = [d for d in os.listdir(model_base) if os.path.isdir(os.path.join(model_base, d))]\n", "\n", "print(f'Total model directories: {len(model_dirs)}')\n", "print(f'Expected: 44 (22 symbols × 2 timeframes)')\n", "\n", "complete = 0\n", "for model_dir in model_dirs:\n", "    path = os.path.join(model_base, model_dir)\n", "    has_clf = os.path.exists(os.path.join(path, 'classification.h5'))\n", "    has_params = os.path.exists(os.path.join(path, 'params.json'))\n", "    \n", "    if has_clf and has_params:\n", "        complete += 1\n", "\n", "print(f'Complete models: {complete}/{len(model_dirs)}')\n", "\n", "print(f'\\nModel size check:')\n", "for model_dir in sorted(model_dirs)[:3]:\n", "    path = os.path.join(model_base, model_dir)\n", "    clf_path = os.path.join(path, 'classification.h5')\n", "    if os.path.exists(clf_path):\n", "        size_mb = os.path.getsize(clf_path) / 1024 / 1024\n", "        print(f'  {model_dir}: {size_mb:.1f} MB')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Done!\n", "\n", "All 44 classification models trained and saved to Google Drive.\n", "Ready for next step: detection model training or deployment.\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": [""]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"name": "python", "version": "3.11.0"}}, "nbformat": 4, "nbformat_minor": 5}