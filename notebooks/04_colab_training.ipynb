{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# Crypto ZigZag ML - GPU Training on Google Colab\n", "\n", "This notebook runs on Google Colab with free GPU support.\n", "\n", "Instructions:\n", "1. Open this notebook in Google Colab\n", "2. Run all cells in order\n", "3. GPU will be enabled automatically\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Step 1: Setup and Mount Google Drive\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Check GPU availability\n", "import tensorflow as tf\n", "\n", "print(f'GPU Available: {len(tf.config.list_physical_devices(\"GPU\"))}')\n", "print(f'GPU Devices: {tf.config.list_physical_devices(\"GPU\")}')\n", "\n", "# Mount Google Drive\n", "from google.colab import drive\n", "drive.mount('/content/drive')"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Clone repository if needed\n", "!cd /content/drive/MyDrive && git clone https://github.com/caizongxun/crypto-zigzag-ml.git\n", "!cd /content/drive/MyDrive/crypto-zigzag-ml && pip install -q -r requirements.txt"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Step 2: Import Libraries and Setup Paths\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import sys\n", "from pathlib import Path\n", "\n", "# Add project to path\n", "project_root = '/content/drive/MyDrive/crypto-zigzag-ml'\n", "sys.path.insert(0, project_root)\n", "\n", "import pandas as pd\n", "import numpy as np\n", "import tensorflow as tf\n", "from tensorflow import keras\n", "\n", "from data.fetch_data import CryptoDataFetcher\n", "from src.zigzag_indicator import ZigZagIndicator\n", "from src.features import FeatureEngineer\n", "from src.models import LSTMXGBoostModel\n", "from src.utils import normalize_data, time_series_split\n", "\n", "print('All imports successful!')\n", "print(f'TensorFlow version: {tf.__version__}')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Step 3: Fetch Data\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print('Fetching BTCUSDT 15m data...')\n", "fetcher = CryptoDataFetcher()\n", "btc_15m = fetcher.fetch_symbol_timeframe('BTCUSDT', '15m')\n", "print(f'Data shape: {btc_15m.shape}')\n", "print(f'Date range: {btc_15m.index.min()} to {btc_15m.index.max()}')"]
 }, {"cell_type": "markdown", "metadata": {}, "source": ["## Step 4: Apply ZigZag and Features\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print('Applying ZigZag...')\n", "zigzag = ZigZagIndicator(depth=12, deviation=5, backstep=2)\n", "btc_15m = zigzag.label_kbars(btc_15m)\n", "\n", "print('Label distribution:')\n", "for label_id, count in btc_15m['zigzag_label'].value_counts().sort_index().items():\n", "    print(f'  {zigzag.get_label_name(label_id)}: {count}')\n", "\n", "print('\\nApplying feature engineering...')\n", "fe = FeatureEngineer(lookback_periods=[5, 10, 20, 50, 200])\n", "btc_15m = fe.calculate_all_features(btc_15m)\n", "\n", "feature_cols = fe.get_feature_columns(btc_15m)\n", "btc_15m[feature_cols] = btc_15m[feature_cols].fillna(method='ffill').fillna(0)\n", "\n", "print(f'Total features: {len(feature_cols)}')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Step 5: Prepare Training Data\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Select important features and limit data size for GPU memory\n", "print('Preparing data for training...')\n", "\n", "# Use top 40 features\n", "selected_features = feature_cols[:40]\n", "\n", "# Time series split\n", "train_df, val_df, test_df = time_series_split(btc_15m, train_ratio=0.7, validation_ratio=0.15)\n", "\n", "# Extract features and labels\n", "X_train = train_df[selected_features].values\n", "y_train = train_df['zigzag_label'].values\n", "X_val = val_df[selected_features].values\n", "y_val = val_df['zigzag_label'].values\n", "X_test = test_df[selected_features].values\n", "y_test = test_df['zigzag_label'].values\n", "\n", "print(f'Train: {X_train.shape}, Val: {X_val.shape}, Test: {X_test.shape}')\n", "\n", "# Normalize\n", "print('Normalizing...')\n", "X_train = X_train.astype(np.float32)\n", "X_val = X_val.astype(np.float32)\n", "X_test = X_test.astype(np.float32)\n", "\n", "mean = X_train.mean(axis=0)\n", "std = X_train.std(axis=0) + 1e-8\n", "\n", "X_train = (X_train - mean) / std\n", "X_val = (X_val - mean) / std\n", "X_test = (X_test - mean) / std\n", "\n", "print('Data normalized')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Step 6: Create Sequences\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def create_sequences(X, y, timesteps=20):\n", "    X_seq, y_seq = [], []\n", "    for i in range(len(X) - timesteps):\n", "        X_seq.append(X[i:(i + timesteps)])\n", "        y_seq.append(y[i + timesteps])\n", "    return np.array(X_seq, dtype=np.float32), np.array(y_seq)\n", "\n", "print('Creating sequences (timesteps=20)...')\n", "X_train_seq, y_train_seq = create_sequences(X_train, y_train, timesteps=20)\n", "X_val_seq, y_val_seq = create_sequences(X_val, y_val, timesteps=20)\n", "X_test_seq, y_test_seq = create_sequences(X_test, y_test, timesteps=20)\n", "\n", "print(f'Train sequences: {X_train_seq.shape}')\n", "print(f'Val sequences: {X_val_seq.shape}')\n", "print(f'Test sequences: {X_test_seq.shape}')\n", "\n", "# Check class distribution\n", "unique, counts = np.unique(y_train_seq, return_counts=True)\n", "print(f'\\nClass distribution in training:')\n", "for u, c in zip(unique, counts):\n", "    print(f'  Class {u}: {c} ({100*c/len(y_train_seq):.1f}%)')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Step 7: Calculate Class Weights\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Calculate class weights to handle imbalanced data\n", "from sklearn.utils.class_weight import compute_class_weight\n", "\n", "print('Calculating class weights...')\n", "\n", "class_weights = compute_class_weight('balanced', classes=np.unique(y_train_seq), y=y_train_seq)\n", "class_weight_dict = {i: w for i, w in enumerate(class_weights)}\n", "\n", "print('Class weights:')\n", "for cls, weight in class_weight_dict.items():\n", "    print(f'  Class {cls}: {weight:.4f}')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Step 8: Build and Train LSTM Model\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print('Building LSTM model...')\n", "\n", "model = keras.Sequential([\n", "    keras.layers.LSTM(128, input_shape=(X_train_seq.shape[1], X_train_seq.shape[2]), return_sequences=True),\n", "    keras.layers.Dropout(0.2),\n", "    keras.layers.LSTM(64, return_sequences=False),\n", "    keras.layers.Dropout(0.2),\n", "    keras.layers.Dense(32, activation='relu'),\n", "    keras.layers.Dropout(0.2),\n", "    keras.layers.Dense(5, activation='softmax')  # 5 classes: NO_SIGNAL, HH, HL, LH, LL\n", "])\n", "\n", "model.compile(\n", "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n", "    loss='sparse_categorical_crossentropy',\n", "    metrics=['accuracy']\n", ")\n", "\n", "print(model.summary())"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print('Starting training with class weights on GPU...')\n", "\n", "early_stop = keras.callbacks.EarlyStopping(\n", "    monitor='val_loss',\n", "    patience=20,\n", "    restore_best_weights=True,\n", "    verbose=1\n", ")\n", "\n", "history = model.fit(\n", "    X_train_seq, y_train_seq,\n", "    validation_data=(X_val_seq, y_val_seq),\n", "    epochs=200,\n", "    batch_size=64,\n", "    class_weight=class_weight_dict,  # Use class weights\n", "    callbacks=[early_stop],\n", "    verbose=1\n", ")\n", "\n", "print('\\nTraining complete!')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Step 9: Evaluate Model\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Training accuracy\n", "train_loss, train_acc = model.evaluate(X_train_seq, y_train_seq, verbose=0)\n", "print(f'Train Accuracy: {train_acc:.4f}')\n", "\n", "# Validation accuracy\n", "val_loss, val_acc = model.evaluate(X_val_seq, y_val_seq, verbose=0)\n", "print(f'Val Accuracy: {val_acc:.4f}')\n", "\n", "# Test accuracy\n", "test_loss, test_acc = model.evaluate(X_test_seq, y_test_seq, verbose=0)\n", "print(f'Test Accuracy: {test_acc:.4f}')\n", "\n", "# Predictions\n", "y_pred = model.predict(X_test_seq, verbose=0)\n", "y_pred_labels = np.argmax(y_pred, axis=1)\n", "\n", "# Classification metrics\n", "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix, classification_report\n", "\n", "print(f'\\nPrecision: {precision_score(y_test_seq, y_pred_labels, average=\"weighted\", zero_division=0):.4f}')\n", "print(f'Recall: {recall_score(y_test_seq, y_pred_labels, average=\"weighted\", zero_division=0):.4f}')\n", "print(f'F1-Score: {f1_score(y_test_seq, y_pred_labels, average=\"weighted\", zero_division=0):.4f}')\n", "\n", "print(f'\\nConfusion Matrix:')\n", "cm = confusion_matrix(y_test_seq, y_pred_labels)\n", "print(cm)\n", "\n", "print(f'\\nClassification Report:')\n", "print(classification_report(y_test_seq, y_pred_labels, zero_division=0))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Step 10: Save Model\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Save to Google Drive\n", "model_path = '/content/drive/MyDrive/crypto-zigzag-ml/models/lstm_model_balanced.h5'\n", "model.save(model_path)\n", "print(f'Model saved to: {model_path}')\n", "\n", "# Save normalization parameters\n", "import pickle\n", "norm_params = {'mean': mean, 'std': std}\n", "params_path = '/content/drive/MyDrive/crypto-zigzag-ml/models/norm_params_balanced.pkl'\n", "with open(params_path, 'wb') as f:\n", "    pickle.dump(norm_params, f)\n", "print(f'Normalization parameters saved to: {params_path}')\n", "\n", "# Save training history\n", "history_dict = {\n", "    'train_loss': history.history['loss'],\n", "    'val_loss': history.history['val_loss'],\n", "    'train_acc': history.history['accuracy'],\n", "    'val_acc': history.history['val_accuracy']\n", "}\n", "history_path = '/content/drive/MyDrive/crypto-zigzag-ml/models/training_history.pkl'\n", "with open(history_path, 'wb') as f:\n", "    pickle.dump(history_dict, f)\n", "print(f'Training history saved to: {history_path}')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Done!\n", "\n", "Your trained balanced LSTM model is ready. Download it from Google Drive and use it for predictions!\n", "\n", "Models saved:\n", "- lstm_model_balanced.h5 (the trained model)\n", "- norm_params_balanced.pkl (normalization parameters)\n", "- training_history.pkl (training metrics)\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": [""]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"name": "python", "version": "3.11.0"}}, "nbformat": 4, "nbformat_minor": 5}