{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# Test Notebook - BTC 15m Model Training\n", "\n", "This notebook tests the complete training pipeline with BTC USDT 15-minute data.\n", "\n", "Before running batch training on all 44 symbol-timeframe combinations,\n", "we test with a single one to validate the pipeline.\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Step 1: Setup and Imports\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import tensorflow as tf\n", "print(f'TensorFlow Version: {tf.__version__}')\n", "print(f'GPU Available: {len(tf.config.list_physical_devices(\"GPU\"))}')\n", "print(f'GPU Devices: {tf.config.list_physical_devices(\"GPU\")}')\n", "\n", "from google.colab import drive\n", "drive.mount('/content/drive')"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import sys\n", "import os\n", "\n", "project_root = '/content/drive/MyDrive/crypto-zigzag-ml'\n", "sys.path.insert(0, project_root)\n", "\n", "# Create necessary directories\n", "os.makedirs(f'{project_root}/models/btcusdt_15m', exist_ok=True)\n", "os.makedirs(f'{project_root}/training_logs', exist_ok=True)\n", "\n", "import pandas as pd\n", "import numpy as np\n", "import json\n", "from datetime import datetime\n", "from tensorflow import keras\n", "from tensorflow.keras import layers\n", "\n", "from data.fetch_data import CryptoDataFetcher\n", "from src.zigzag_indicator import ZigZagIndicator\n", "from src.features import FeatureEngineer\n", "from src.utils import time_series_split\n", "\n", "print('\\nAll imports successful!')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Step 2: Fetch BTC 15m Data\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print('Fetching BTC USDT 15m data...')\n", "fetcher = CryptoDataFetcher()\n", "btc_15m = fetcher.fetch_symbol_timeframe('BTCUSDT', '15m')\n", "\n", "print(f'Shape: {btc_15m.shape}')\n", "print(f'Date Range: {btc_15m.index.min()} to {btc_15m.index.max()}')\n", "print(f'Columns: {list(btc_15m.columns)}')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Step 3: Apply ZigZag Labeling\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print('\\nApplying ZigZag Indicator...')\n", "zigzag = ZigZagIndicator(depth=12, deviation=5, backstep=2)\n", "btc_15m = zigzag.label_kbars(btc_15m)\n", "\n", "print('\\nLabel Distribution:')\n", "label_counts = btc_15m['zigzag_label'].value_counts().sort_index()\n", "for label_id, count in label_counts.items():\n", "    label_name = zigzag.get_label_name(label_id)\n", "    pct = 100 * count / len(btc_15m)\n", "    print(f'  {label_name:12s}: {count:6d} ({pct:5.2f}%)')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Step 4: Feature Engineering\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print('\\nEngineering Features...')\n", "fe = FeatureEngineer(lookback_periods=[5, 10, 20, 50, 200])\n", "btc_15m = fe.calculate_all_features(btc_15m)\n", "\n", "feature_cols = fe.get_feature_columns(btc_15m)\n", "btc_15m[feature_cols] = btc_15m[feature_cols].fillna(method='ffill').fillna(0)\n", "\n", "print(f'\\nTotal Features: {len(feature_cols)}')\n", "print(f'Sample Features: {feature_cols[:15]}')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Step 5: Time Series Split\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print('\\nTime Series Split (70-15-15)...')\n", "train_df, val_df, test_df = time_series_split(btc_15m, train_ratio=0.7, validation_ratio=0.15)\n", "\n", "print(f'Train: {len(train_df):6d} bars ({100*len(train_df)/len(btc_15m):5.1f}%)')\n", "print(f'Val:   {len(val_df):6d} bars ({100*len(val_df)/len(btc_15m):5.1f}%)')\n", "print(f'Test:  {len(test_df):6d} bars ({100*len(test_df)/len(btc_15m):5.1f}%)')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Step 6: Prepare Training Data\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print('\\nPreparing Training Data...')\n", "\n", "# Select top 40 features\n", "selected_features = feature_cols[:40]\n", "\n", "# Extract\n", "X_train = train_df[selected_features].values.astype(np.float32)\n", "y_train = train_df['zigzag_label'].values\n", "X_val = val_df[selected_features].values.astype(np.float32)\n", "y_val = val_df['zigzag_label'].values\n", "X_test = test_df[selected_features].values.astype(np.float32)\n", "y_test = test_df['zigzag_label'].values\n", "\n", "print(f'X_train: {X_train.shape}')\n", "print(f'y_train: {y_train.shape}')\n", "\n", "# Normalize\n", "print('\\nNormalizing...')\n", "mean = X_train.mean(axis=0)\n", "std = X_train.std(axis=0) + 1e-8\n", "\n", "X_train = (X_train - mean) / std\n", "X_val = (X_val - mean) / std\n", "X_test = (X_test - mean) / std\n", "\n", "print(f'X_train mean: {X_train.mean():.4f}, std: {X_train.std():.4f}')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Step 7: Create Sequences\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def create_sequences(X, y, timesteps=20):\n", "    X_seq, y_seq = [], []\n", "    for i in range(len(X) - timesteps):\n", "        X_seq.append(X[i:(i + timesteps)])\n", "        y_seq.append(y[i + timesteps])\n", "    return np.array(X_seq, dtype=np.float32), np.array(y_seq)\n", "\n", "print('Creating Sequences (timesteps=20)...')\n", "X_train_seq, y_train_seq = create_sequences(X_train, y_train, timesteps=20)\n", "X_val_seq, y_val_seq = create_sequences(X_val, y_val, timesteps=20)\n", "X_test_seq, y_test_seq = create_sequences(X_test, y_test, timesteps=20)\n", "\n", "print(f'X_train_seq: {X_train_seq.shape}')\n", "print(f'X_val_seq: {X_val_seq.shape}')\n", "print(f'X_test_seq: {X_test_seq.shape}')\n", "\n", "# Check class distribution\n", "unique, counts = np.unique(y_train_seq, return_counts=True)\n", "print('\\nClass Distribution in Train Set:')\n", "for u, c in zip(unique, counts):\n", "    pct = 100 * c / len(y_train_seq)\n", "    print(f'  Class {u}: {c:6d} ({pct:5.2f}%)')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Step 8: Calculate Class Weights\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print('\\nCalculating Aggressive Class Weights...')\n", "\n", "unique, counts = np.unique(y_train_seq, return_counts=True)\n", "total = len(y_train_seq)\n", "\n", "class_weights = {}\n", "for u, c in zip(unique, counts):\n", "    if u == 0:  # NO_SIGNAL (majority)\n", "        class_weights[u] = 1.0\n", "    else:  # Signal classes (minority)\n", "        # Aggressive weighting\n", "        weight = total / (5 * c) * 3\n", "        class_weights[u] = weight\n", "\n", "print('\\nClass Weights:')\n", "for cls, weight in sorted(class_weights.items()):\n", "    print(f'  Class {cls}: {weight:.4f}')\n", "\n", "# Binary labels for detection model\n", "y_train_binary = (y_train_seq != 0).astype(np.float32)\n", "y_val_binary = (y_val_seq != 0).astype(np.float32)\n", "y_test_binary = (y_test_seq != 0).astype(np.float32)\n", "\n", "print(f'\\nBinary Signal Distribution:')\n", "print(f'  Train: {y_train_binary.sum():.0f}/{len(y_train_binary)} ({100*y_train_binary.mean():.2f}%)')\n", "print(f'  Val: {y_val_binary.sum():.0f}/{len(y_val_binary)} ({100*y_val_binary.mean():.2f}%)')\n", "print(f'  Test: {y_test_binary.sum():.0f}/{len(y_test_binary)} ({100*y_test_binary.mean():.2f}%)')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Step 9: Build Classification Model\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print('Building Classification Model (5-class)...')\n", "\n", "clf_model = keras.Sequential([\n", "    layers.LSTM(256, input_shape=(X_train_seq.shape[1], X_train_seq.shape[2]), return_sequences=True),\n", "    layers.Dropout(0.3),\n", "    layers.LSTM(128, return_sequences=False),\n", "    layers.Dropout(0.3),\n", "    layers.Dense(64, activation='relu'),\n", "    layers.Dropout(0.3),\n", "    layers.Dense(32, activation='relu'),\n", "    layers.Dropout(0.2),\n", "    layers.Dense(5, activation='softmax')\n", "])\n", "\n", "clf_model.compile(\n", "    optimizer=keras.optimizers.Adam(learning_rate=0.0005),\n", "    loss='sparse_categorical_crossentropy',\n", "    metrics=['accuracy']\n", ")\n", "\n", "print(clf_model.summary())"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Step 10: Build Detection Model\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print('Building Detection Model (binary)...')\n", "\n", "det_model = keras.Sequential([\n", "    layers.LSTM(128, input_shape=(X_train_seq.shape[1], X_train_seq.shape[2]), return_sequences=True),\n", "    layers.Dropout(0.2),\n", "    layers.LSTM(64, return_sequences=False),\n", "    layers.Dropout(0.2),\n", "    layers.Dense(32, activation='relu'),\n", "    layers.Dropout(0.2),\n", "    layers.Dense(1, activation='sigmoid')\n", "])\n", "\n", "det_model.compile(\n", "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n", "    loss='binary_crossentropy',\n", "    metrics=['accuracy']\n", ")\n", "\n", "print(det_model.summary())"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Step 11: Train Classification Model\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print('Training Classification Model...')\n", "\n", "early_stop = keras.callbacks.EarlyStopping(\n", "    monitor='val_loss',\n", "    patience=20,\n", "    restore_best_weights=True,\n", "    verbose=1\n", ")\n", "\n", "reduce_lr = keras.callbacks.ReduceLROnPlateau(\n", "    monitor='val_loss',\n", "    factor=0.5,\n", "    patience=10,\n", "    min_lr=1e-6,\n", "    verbose=1\n", ")\n", "\n", "clf_history = clf_model.fit(\n", "    X_train_seq, y_train_seq,\n", "    validation_data=(X_val_seq, y_val_seq),\n", "    epochs=200,\n", "    batch_size=32,\n", "    class_weight=class_weights,\n", "    callbacks=[early_stop, reduce_lr],\n", "    verbose=1\n", ")\n", "\n", "print('\\nClassification Training Complete!')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Step 12: Train Detection Model\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print('Training Detection Model...')\n", "\n", "det_history = det_model.fit(\n", "    X_train_seq, y_train_binary,\n", "    validation_data=(X_val_seq, y_val_binary),\n", "    epochs=150,\n", "    batch_size=32,\n", "    callbacks=[early_stop, reduce_lr],\n", "    verbose=1\n", ")\n", "\n", "print('\\nDetection Training Complete!')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Step 13: Evaluate Models\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix, classification_report\n", "\n", "print('='*70)\n", "print('CLASSIFICATION MODEL EVALUATION')\n", "print('='*70)\n", "\n", "# Predictions\n", "y_clf_pred = clf_model.predict(X_test_seq, verbose=0)\n", "y_clf_pred_labels = np.argmax(y_clf_pred, axis=1)\n", "\n", "# Metrics\n", "clf_loss, clf_acc = clf_model.evaluate(X_test_seq, y_test_seq, verbose=0)\n", "\n", "print(f'\\nTest Loss: {clf_loss:.4f}')\n", "print(f'Test Accuracy: {clf_acc:.4f}')\n", "print(f'Precision: {precision_score(y_test_seq, y_clf_pred_labels, average=\"weighted\", zero_division=0):.4f}')\n", "print(f'Recall: {recall_score(y_test_seq, y_clf_pred_labels, average=\"weighted\", zero_division=0):.4f}')\n", "print(f'F1-Score: {f1_score(y_test_seq, y_clf_pred_labels, average=\"weighted\", zero_division=0):.4f}')\n", "\n", "print(f'\\nConfusion Matrix:')\n", "cm = confusion_matrix(y_test_seq, y_clf_pred_labels)\n", "print(cm)\n", "\n", "print(f'\\nClassification Report:')\n", "print(classification_report(y_test_seq, y_clf_pred_labels, zero_division=0))\n", "\n", "print('='*70)\n", "print('DETECTION MODEL EVALUATION')\n", "print('='*70)\n", "\n", "# Binary predictions\n", "y_det_pred = det_model.predict(X_test_seq, verbose=0).flatten()\n", "y_det_pred_labels = (y_det_pred > 0.5).astype(int)\n", "\n", "det_loss, det_acc = det_model.evaluate(X_test_seq, y_test_binary, verbose=0)\n", "\n", "print(f'\\nTest Loss: {det_loss:.4f}')\n", "print(f'Test Accuracy: {det_acc:.4f}')\n", "print(f'Precision: {precision_score(y_test_binary, y_det_pred_labels, zero_division=0):.4f}')\n", "print(f'Recall: {recall_score(y_test_binary, y_det_pred_labels, zero_division=0):.4f}')\n", "print(f'F1-Score: {f1_score(y_test_binary, y_det_pred_labels, zero_division=0):.4f}')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Step 14: Save Models\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print('\\nSaving Models...')\n", "\n", "model_dir = f'{project_root}/models/btcusdt_15m'\n", "\n", "# Save classification model\n", "clf_path = f'{model_dir}/classification.h5'\n", "clf_model.save(clf_path)\n", "print(f'  Classification Model: {clf_path}')\n", "\n", "# Save detection model\n", "det_path = f'{model_dir}/detection.h5'\n", "det_model.save(det_path)\n", "print(f'  Detection Model: {det_path}')\n", "\n", "# Save parameters and metrics\n", "params = {\n", "    'symbol': 'BTCUSDT',\n", "    'timeframe': '15m',\n", "    'timestamp': datetime.now().isoformat(),\n", "    'normalization': {\n", "        'mean': mean.tolist(),\n", "        'std': std.tolist()\n", "    },\n", "    'class_weights': {int(k): v for k, v in class_weights.items()},\n", "    'metrics': {\n", "        'classification': {\n", "            'test_loss': float(clf_loss),\n", "            'test_acc': float(clf_acc)\n", "        },\n", "        'detection': {\n", "            'test_loss': float(det_loss),\n", "            'test_acc': float(det_acc)\n", "        }\n", "    }\n", "}\n", "\n", "params_path = f'{model_dir}/params.json'\n", "with open(params_path, 'w') as f:\n", "    json.dump(params, f, indent=2)\n", "print(f'  Parameters: {params_path}')\n", "\n", "print('\\n✓ All models saved successfully!')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Step 15: Summary Report\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print('\\n' + '='*70)\n", "print('TEST TRAINING SUMMARY - BTC USDT 15m')\n", "print('='*70)\n", "\n", "print(f'\\nData:')\n", "print(f'  Total bars: {len(btc_15m)}')\n", "print(f'  Train: {len(train_df)} bars')\n", "print(f'  Val: {len(val_df)} bars')\n", "print(f'  Test: {len(test_df)} bars')\n", "\n", "print(f'\\nFeatures:')\n", "print(f'  Total: {len(feature_cols)}')\n", "print(f'  Selected: {len(selected_features)}')\n", "\n", "print(f'\\nSequences:')\n", "print(f'  Timesteps: 20')\n", "print(f'  Train sequences: {len(X_train_seq)}')\n", "print(f'  Val sequences: {len(X_val_seq)}')\n", "print(f'  Test sequences: {len(X_test_seq)}')\n", "\n", "print(f'\\nModels:')\n", "print(f'  Classification (5-class): {clf_path}')\n", "print(f'    Test Accuracy: {clf_acc:.4f}')\n", "print(f'  Detection (Binary): {det_path}')\n", "print(f'    Test Accuracy: {det_acc:.4f}')\n", "\n", "print(f'\\nParameters:')\n", "print(f'  Saved: {params_path}')\n", "\n", "print('='*70)\n", "print('✓ TEST SUCCESSFUL - READY FOR BATCH TRAINING')\n", "print('='*70)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": [""]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"name": "python", "version": "3.11.0"}}, "nbformat": 4, "nbformat_minor": 5}